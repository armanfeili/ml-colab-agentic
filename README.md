# ML Colab Agentic Template

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/armanfeili/ml-colab-agentic/blob/main/notebooks/01_train.ipynb)

**A minimal, Drive-first template for training ML models in Google Colab with free GPUs.**

- ğŸ¯ **Code on GitHub** â€” version control with Copilot support
- ğŸ’¾ **Storage on Google Drive** â€” datasets, runs, checkpoints persist across sessions
- ğŸš€ **Run in Colab** â€” free T4/A100 GPUs, no local setup required
- ğŸ”„ **Reproducible** â€” frozen configs, deterministic seeds, structured outputs

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LOCAL (VS Code + Copilot)                                      â”‚
â”‚  â”œâ”€ Edit src/utils.py, notebooks/                              â”‚
â”‚  â”œâ”€ Commit & push to GitHub                                    â”‚
â”‚  â””â”€ No data/runs stored here                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COLAB VM (/content/)                                           â”‚
â”‚  â”œâ”€ Clone repo from GitHub (code only)                         â”‚
â”‚  â”œâ”€ Mount Google Drive at /content/drive                       â”‚
â”‚  â””â”€ Run training â†’ outputs to Drive                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GOOGLE DRIVE (MyDrive/ml-colab-agentic/)                      â”‚
â”‚  â”œâ”€ data/raw/                  â† datasets cached here          â”‚
â”‚  â”œâ”€ data/processed/             â† preprocessed data            â”‚
â”‚  â”œâ”€ runs/<timestamp_dataset_model>/  â† per-run outputs         â”‚
â”‚  â”‚   â”œâ”€ cfg.yaml               â† frozen config                 â”‚
â”‚  â”‚   â”œâ”€ metrics.csv            â† epoch-wise metrics            â”‚
â”‚  â”‚   â”œâ”€ checkpoints/           â† model weights (.pt files)     â”‚
â”‚  â”‚   â”œâ”€ plots/                 â† learning curves, etc.         â”‚
â”‚  â”‚   â””â”€ artifacts/             â† confusion matrices, etc.      â”‚
â”‚  â””â”€ latest/run/                â† pointer to most recent run    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Principle:** Code travels through Git. Data stays in Drive.

---

## Quick Start (3 steps)

### 1. Open in Colab
Click the badge above or go to:
```
https://colab.research.google.com/github/armanfeili/ml-colab-agentic/blob/main/notebooks/01_train.ipynb
```

### 2. Enable GPU
- **Runtime** â†’ **Change runtime type** â†’ **GPU** (T4 or A100) â†’ **Save**

### 3. Run All Cells
- **Section A**: Mounts Drive, clones repo, installs dependencies
- **Section B**: Creates timestamped run folder, freezes config
- **Section C**: Trains model (5 epochs Ã— ~10 sec = ~1 min)
- **Section D**: Shows metrics and artifacts

**First run downloads CIFAR-10** (~160 MB) to Drive â€” subsequent runs reuse it.

---

## Repository Structure (Code Only)

```
ml-colab-agentic/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_train.ipynb       # Colab entry point (run this!)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ utils.py             # Training loop, model, dataloaders
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_smoke.py        # Basic smoke tests
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ QUICK_START.md       # Detailed setup guide
â”œâ”€â”€ requirements.txt         # Dependencies (torch, pyyaml, etc.)
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md                # This file
```

**Not in repo:** `data/`, `runs/`, `outputs/`, `checkpoints/`, `*.pt` (all in Drive or `.gitignore`)

---

## Google Drive Structure (Storage Only)

Created automatically on first run:

```
MyDrive/ml-colab-agentic/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # Downloaded datasets (e.g., CIFAR-10)
â”‚   â””â”€â”€ processed/                    # Preprocessed datasets
â”œâ”€â”€ runs/
â”‚   â”œâ”€â”€ 2025-10-31_14-20_cifar10_simplenet_amp/
â”‚   â”‚   â”œâ”€â”€ cfg.yaml                  # Frozen config for this run
â”‚   â”‚   â”œâ”€â”€ metrics.csv               # Train/val loss & accuracy per epoch
â”‚   â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â”‚   â”œâ”€â”€ best.pt               # Best model (by val accuracy)
â”‚   â”‚   â”‚   â”œâ”€â”€ epoch_001.pt
â”‚   â”‚   â”‚   â””â”€â”€ epoch_005.pt
â”‚   â”‚   â”œâ”€â”€ plots/                    # Learning curves, etc.
â”‚   â”‚   â”œâ”€â”€ artifacts/                # Test predictions, confusion matrices
â”‚   â”‚   â””â”€â”€ cache/                    # Temporary files
â”‚   â””â”€â”€ 2025-11-01_09-15_cifar10_simplenet_amp/  # Next run
â””â”€â”€ latest/
    â””â”€â”€ run/                          # Pointer to most recent run
```

---

## How It Works

### A. Setup (Notebook Section A)
1. **Mount Drive** â†’ `/content/drive/MyDrive/ml-colab-agentic/`
2. **Clone/pull repo** â†’ `/content/ml-colab-agentic/` (fresh code from GitHub)
3. **Install dependencies** â†’ `pip install -r requirements.txt`
4. **Import utilities** â†’ `from src.utils import ...`

### B. Run Config (Section B)
```python
CFG = {
    "seed": 42,
    "epochs": 5,
    "batch_size": 128,
    "lr": 1e-3,
    "dataset": "CIFAR10",
    "data_root": f"{DATA_DIR}/raw",  # Points to Drive
    "num_workers": 2,
    "amp": True,
}
```
- Creates timestamped folder: `runs/2025-10-31_14-20_cifar10_simplenet_amp/`
- Saves `cfg.yaml` to Drive for reproducibility

### C. Train (Section C)
- Loads CIFAR-10 from `data_root` (downloads if missing)
- Trains `SimpleNet` (3-layer CNN) for 5 epochs
- Saves checkpoints to `runs/<run_id>/checkpoints/`
- Logs metrics to `runs/<run_id>/metrics.csv`

### D. Inspect (Section D)
- Shows metrics as pandas DataFrame
- Lists all artifacts in Drive folder

---

## Customization

### Change Dataset
1. Edit `CFG["dataset"]` in notebook
2. Add loader in `src/utils.py`:
```python
def prepare_dataloaders_imagenet(root, batch_size, num_workers):
    # Your custom dataset logic
    return train_loader, test_loader
```

### Train Longer
```python
CFG = {
    "epochs": 20,
    "batch_size": 64,  # Reduce if OOM
}
```

### Use Your Own Model
In `src/utils.py`, replace `SimpleNet` or add new class:
```python
class MyModel(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        # Your architecture
```

Then in notebook:
```python
model = MyModel(num_classes=10).to(device)
```

---

## Local Development (Optional)

### 1. Clone Repo
```bash
git clone https://github.com/armanfeili/ml-colab-agentic.git
cd ml-colab-agentic
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Edit Code Locally
- Use **VS Code** with **GitHub Copilot** for AI-assisted development
- Modify `src/utils.py`, add features to notebook
- Commit changes:
```bash
git add .
git commit -m "feat: add custom dataset loader"
git push
```

### 4. Pull in Colab
Next Colab run (Section A2) automatically pulls latest code from GitHub.

---

## Tips & Best Practices

### âœ… Do
- **Edit code locally** (VS Code + Copilot) â†’ commit â†’ pull in Colab
- **Store all data/runs in Drive** â†’ survives Colab session resets
- **Use timestamped run folders** â†’ never overwrite previous experiments
- **Check GPU allocation** â†’ Runtime â†’ Change runtime type â†’ GPU (T4 or A100)

### âŒ Don't
- **Don't commit large files** (`.pt`, datasets) â†’ they're `.gitignore`d
- **Don't edit code in Colab UI** â†’ changes won't sync to GitHub
- **Don't rely on Colab VM storage** â†’ it's ephemeral (deleted after 12h idle)

---

## Troubleshooting

| Issue | Solution |
|-------|----------|
| `CUDA not available` | Runtime â†’ Change runtime type â†’ GPU (T4) |
| `Drive mount fails` | Re-run cell A0, authenticate in popup |
| `OOM error` | Reduce `batch_size` (try 64 or 32) |
| `Git pull fails` | Check repo URL in A2, ensure `main` branch exists |
| `Module not found` | Re-run A3 (`pip install -r requirements.txt`) |
| `CIFAR-10 download slow` | First run only; cached in `data/raw/` for future runs |

---

## What's Different About This Template?

1. **Drive-first storage** â€” no repo clutter with datasets/checkpoints
2. **Code-only Git** â€” clean version control (12 files tracked vs. typical 100+)
3. **Reproducible runs** â€” timestamped folders + frozen YAML configs
4. **Copilot-ready** â€” develop locally, run remotely with ease
5. **Zero local setup** â€” works entirely in browser (Colab)

---

## Contributing

1. Fork the repo
2. Create a feature branch: `git checkout -b feat/amazing-feature`
3. Commit changes: `git commit -m "feat: add amazing feature"`
4. Push to branch: `git push origin feat/amazing-feature`
5. Open a Pull Request

---

## Creator

Created by **[Arman Feili](https://github.com/armanfeili)** â€” ML Engineer & AI Enthusiast

---

## License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

---

## See Also

- [docs/QUICK_START.md](docs/QUICK_START.md) â€” Detailed walkthrough
- [notebooks/01_train.ipynb](notebooks/01_train.ipynb) â€” Main training notebook
- [src/utils.py](src/utils.py) â€” Core training utilities
